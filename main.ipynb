{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import Set\n",
    "import Utility\n",
    "import SQLSentence\n",
    "import Model\n",
    "from models import FullyConnected, TCN, CNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Environment\n",
    "connect = Utility.connect_to_database()\n",
    "main_data, list_stock_type, dict_code_name, dict_type_name = Utility.fetch_data_from_db()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Constants\n",
    "PATH_CHECKPOINT = 'checkpoint'\n",
    "\n",
    "if not os.path.exists(PATH_CHECKPOINT):\n",
    "    os.makedirs(PATH_CHECKPOINT)\n",
    "\n",
    "myseed = 42069  # set a random seed for reproducibility\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Functions\n",
    "\n",
    "# Dataset\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.shape = data.shape\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.tensor(self.data[index], dtype=torch.float32)\n",
    "        label = torch.tensor(self.label[index], dtype=torch.float32)\n",
    "\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "# Invoke Model\n",
    "def invoke_model(mode, model, dataloader, criterion, device, optimizer=None, threshold=0.0):\n",
    "    \n",
    "    model.train() if mode == 'train' else model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_count, correct_count = 0, 0\n",
    "    true_positive, false_positive = 0, 0\n",
    "    true_negative, false_negative = 0, 0\n",
    "\n",
    "    for input, label in dataloader:\n",
    "        input, label = input.to(device), label.to(device)\n",
    " \n",
    "        if mode == 'train' and optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input).to(device)\n",
    "        loss = criterion(outputs.squeeze(1), label)\n",
    "        total_loss+=loss.detach().cpu().item()\n",
    "        \n",
    "        predicted = (outputs.squeeze(1) > threshold).to(torch.bool)\n",
    "        label = label.to(torch.bool)\n",
    "\n",
    "        if mode == 'train' and optimizer is not None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_count += label.size(0)\n",
    "        correct_count += (label == predicted).sum().item()\n",
    "\n",
    "        # TP: both of label and predicted should be 1\n",
    "        true_positive += (label & predicted).sum().item()\n",
    "\n",
    "        # FP: label is 0 and predicted is 1\n",
    "        false_positive += (~label & predicted).sum().item()\n",
    "\n",
    "        # TN: both of label and predicted should be 0\n",
    "        true_negative += (~label & ~predicted).sum().item()\n",
    "\n",
    "        # FN: label is 1 and predicted is 0\n",
    "        false_negative += (label & ~predicted).sum().item()\n",
    "\n",
    "    avg_loss = round(total_loss/len(dataloader), 6)\n",
    "    accuracy = round((correct_count/total_count)*100 , 2)\n",
    "\n",
    "    # Precision: (TP) / (TP + FP)\n",
    "    # precision = round((true_positive/(true_positive+false_positive)) * 100, 2)\n",
    "    precision = 0.0 if (true_positive + false_positive) == 0 else round((true_positive / (true_positive + false_positive)) * 100, 2)\n",
    "    \n",
    "    # Recall:    (TP) / (TP + FN)\n",
    "    # recall = round((true_positive/(true_positive+false_negative)) * 100, 2)\n",
    "    recall = 0.0 if (true_positive + false_negative) == 0 else round((true_positive / (true_positive + false_negative)) * 100, 2)\n",
    "\n",
    "    # print(f'{mode} Loss: {avg_loss}, Accuracy: {accuracy}%, False Positive Accuracy: {fp_acc}%, False Negative Accuracy: {fn_acc}%')\n",
    "\n",
    "    return avg_loss, accuracy, precision, recall\n",
    "\n",
    "# Invoke Model with single stock data\n",
    "def invoke_model_single_stock(mode, model, dataloader, criterion, device, optimizer=None, threshold=0.0):\n",
    "    \n",
    "    model.train() if mode == 'train' else model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_count, correct_count = 0, 0\n",
    "    true_positive, false_positive = 0, 0\n",
    "    true_negative, false_negative = 0, 0\n",
    "\n",
    "    for input, label in tqdm.tqdm(dataloader):\n",
    "        input, label = input.to(device), label.to(device)\n",
    " \n",
    "        if mode == 'train' and optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input).to(device)\n",
    "        loss = criterion(outputs.squeeze(1), label)\n",
    "        total_loss+=loss.detach().cpu().item()\n",
    "        \n",
    "        predicted = (outputs.squeeze(1) > threshold).to(torch.bool)\n",
    "        label = label.to(torch.bool)\n",
    "\n",
    "        if mode == 'train' and optimizer is not None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_count += label.size(0)\n",
    "        correct_count += (label == predicted).sum().item()\n",
    "\n",
    "        # TP: both of label and predicted should be 1\n",
    "        true_positive += (label & predicted).sum().item()\n",
    "\n",
    "        # FP: label is 0 and predicted is 1\n",
    "        false_positive += (~label & predicted).sum().item()\n",
    "\n",
    "        # TN: both of label and predicted should be 0\n",
    "        true_negative += (~label & ~predicted).sum().item()\n",
    "\n",
    "        # FN: label is 1 and predicted is 0\n",
    "        false_negative += (label & ~predicted).sum().item()\n",
    "\n",
    "    avg_loss = round(total_loss/len(dataloader), 6)\n",
    "    accuracy = round((correct_count/total_count)*100 , 2)\n",
    "\n",
    "    # Precision: (TP) / (TP + FP)\n",
    "    # precision = round((true_positive/(true_positive+false_positive)) * 100, 2)\n",
    "    precision = 0.0 if (true_positive + false_positive) == 0 else round((true_positive / (true_positive + false_positive)) * 100, 2)\n",
    "    \n",
    "    # Recall:    (TP) / (TP + FN)\n",
    "    # recall = round((true_positive/(true_positive+false_negative)) * 100, 2)\n",
    "    recall = 0.0 if (true_positive + false_negative) == 0 else round((true_positive / (true_positive + false_negative)) * 100, 2)\n",
    "\n",
    "    # print(f'{mode} Loss: {avg_loss}, Accuracy: {accuracy}%, False Positive Accuracy: {fp_acc}%, False Negative Accuracy: {fn_acc}%')\n",
    "\n",
    "    return avg_loss, accuracy, precision, recall\n",
    "\n",
    "def process_stock_data(stock_data, target, window_length, predict = False):\n",
    "    stock_data = stock_data.drop(['code', 'date'], axis=1).reset_index(drop=True)\n",
    "\n",
    "    index_col_open = stock_data.columns.get_loc(\"open\")\n",
    "    index_col_high = stock_data.columns.get_loc(\"high\")\n",
    "    index_col_low = stock_data.columns.get_loc(\"low\")\n",
    "    index_col_volume = stock_data.columns.get_loc(\"volume\")\n",
    "\n",
    "    stock_data = Set.Feature(stock_data)\n",
    "    stock_data = stock_data.dropna()\n",
    "    stock_data = stock_data.to_numpy()\n",
    "\n",
    "    data_merged = []\n",
    "    label_merged = []\n",
    "\n",
    "    if predict:\n",
    "        return stock_data[-window_length:, index_col_volume + 1:]\n",
    "\n",
    "    for i in range(len(stock_data) - window_length):\n",
    "        data = stock_data[i:i + window_length, index_col_volume + 1:]\n",
    "\n",
    "        if target >= 0:\n",
    "            target_value = (stock_data[i + window_length, index_col_high] - stock_data[i + window_length, index_col_open]) / \\\n",
    "                stock_data[i + window_length, index_col_open]\n",
    "            label = int(target_value >= target)\n",
    "        else:\n",
    "            target_value = (stock_data[i + window_length, index_col_low] - stock_data[i + window_length, index_col_open]) / \\\n",
    "                stock_data[i + window_length, index_col_open]\n",
    "            label = int(target_value <= target)\n",
    "\n",
    "        data_merged.append(data)\n",
    "        label_merged.append(label)\n",
    "\n",
    "    return np.array(data_merged), np.array(label_merged)\n",
    "\n",
    "def build_dataset(main_data, code_list, target, window_length):\n",
    "    all_train_data = []\n",
    "    all_test_data = []\n",
    "\n",
    "    all_train_label = []\n",
    "    all_test_label = []\n",
    "\n",
    "    for code in code_list:\n",
    "        stock_data = main_data[main_data['code'] == code].copy()\n",
    "\n",
    "        data, label = process_stock_data(stock_data, target, window_length)\n",
    "        train_size = int(0.9 * len(data))\n",
    "               \n",
    "        train_data = data[:train_size]\n",
    "        test_data = data[train_size:]\n",
    "\n",
    "        train_label = label[:train_size]\n",
    "        test_label = label[train_size:]\n",
    "\n",
    "        all_train_data.extend(train_data)\n",
    "        all_test_data.extend(test_data)\n",
    "\n",
    "        all_train_label.extend(train_label)\n",
    "        all_test_label.extend(test_label)\n",
    "    \n",
    "    return np.array(all_train_data), np.array(all_test_data), np.array(all_train_label), np.array(all_test_label)\n",
    "\n",
    "def build_dataloader(main_data, code_list, config):\n",
    "\n",
    "    target = config['target_pct']\n",
    "    batch_size = config['batch_size']\n",
    "    window_length = config['window_length']\n",
    "\n",
    "    train_data, test_data, train_label, test_label = build_dataset(main_data, code_list, target, window_length)\n",
    "    dataset_train = StockDataset(train_data, train_label)\n",
    "    dataset_test = StockDataset(test_data, test_label)\n",
    "    datalaoder_train = DataLoader(dataset_train, batch_size, shuffle=True)\n",
    "    datalaoder_test = DataLoader(dataset_test, batch_size, shuffle=False)\n",
    "\n",
    "    return datalaoder_train, datalaoder_test\n",
    "\n",
    "def predict_result(main_data, code, model, device, target, window_length, min_period=100):\n",
    "    stock_data = main_data[main_data['code'] == code].tail(min_period).copy()\n",
    "    data = process_stock_data(stock_data, target, window_length, predict=True)\n",
    "    output = model(torch.tensor(data, dtype=torch.float32).unsqueeze(0).to(device))\n",
    "    return round(output[0].cpu().detach().item(), 4)\n",
    "\n",
    "def GetDatasetShape(main_data, window_length, code=1101, min_period=100):\n",
    "    stock_data = main_data[main_data['code'] == code].tail(min_period).copy()\n",
    "    stock_data = stock_data.drop(['code', 'date'], axis=1).reset_index(drop=True)\n",
    "    stock_data = Set.Feature(stock_data)\n",
    "    stock_data = stock_data.dropna()\n",
    "\n",
    "    index_col_volume = stock_data.columns.get_loc(\"volume\")\n",
    "\n",
    "    stock_data = stock_data.to_numpy()\n",
    "\n",
    "    return np.expand_dims(stock_data[-window_length:, index_col_volume + 1:], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select single Type to adjust the model and the optimizer\n",
    "dict_model = {\n",
    "    0: CNNLSTM,\n",
    "    1: TCN,\n",
    "    2: FullyConnected,\n",
    "}\n",
    "\n",
    "model_type_id = 1\n",
    "stock_industry_type_id = 0\n",
    "config_model = {\n",
    "    'n_epochs': 1,\n",
    "    'batch_size': 256,\n",
    "    'version': 4,\n",
    "    'threshold': 0.0,\n",
    "    'target_pct': 0.02,\n",
    "    'window_length':20,\n",
    "    'scale_weight': 0.8,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'use_checkpoint': False,\n",
    "}\n",
    "\n",
    "list_unique_code_from_data = (SQLSentence.GetCodeByTypeId(stock_industry_type_id, connect))['code'].tolist()\n",
    "datalaoder_train, datalaoder_test = build_dataloader(main_data, list_unique_code_from_data, config_model)\n",
    "\n",
    "model = dict_model[model_type_id](datalaoder_train.dataset.shape).to(device)\n",
    "\n",
    "current_pos_weight = (math.log((Set.GetInfo('pos_weight'))[config_model['target_pct']][dict_type_name[stock_industry_type_id]])+1)*config_model['scale_weight']\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([current_pos_weight]).to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config_model['learning_rate'], weight_decay=config_model['weight_decay'])\n",
    "\n",
    "path_model_records = f'models/model_records/model_records.csv'\n",
    "path_model_checkpoint = f'models/checkpoint/type_{stock_industry_type_id}/type_{stock_industry_type_id}_{model.get_model_name()}_Target_{int(config_model[\"target_pct\"]*100)}_v{str(config_model[\"version\"])}'\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "best_test_loss = Utility.load_best_model_record_txt(stock_industry_type_id, config_model['target_pct'], model.get_model_name(), config_model['version'], path_model_records)\n",
    "\n",
    "if config_model['use_checkpoint']:\n",
    "    try:\n",
    "        postfix='save'\n",
    "        model.load(f\"{path_model_checkpoint}_{postfix}\")\n",
    "    except:\n",
    "        print(f'No preserved model: {model.get_model_name()}')\n",
    "\n",
    "epoch = 0\n",
    "while epoch < config_model['n_epochs']:\n",
    "    epoch+=1\n",
    "    print(f'Train {dict_type_name[stock_industry_type_id]} Epoch: {epoch}')\n",
    "\n",
    "    # Train\n",
    "    train_loss, train_acc, train_precision, train_recall = invoke_model_single_stock('train', model, datalaoder_train, criterion, device, optimizer, config_model['threshold'])\n",
    "    print(f'Loss: {train_loss}, Accuracy: {train_acc}%, Precision: {train_precision}%, Recall: {train_recall}%\\n')\n",
    "\n",
    "    # Test\n",
    "    with torch.no_grad():\n",
    "        test_loss, test_acc, test_precision, test_recall = invoke_model_single_stock('test', model, datalaoder_test, criterion, device, threshold=config_model['threshold'])\n",
    "        print(f'Loss: {test_loss}, Accuracy: {test_acc}%, Precision: {test_precision}%, Recall: {test_recall}%\\n')\n",
    "\n",
    "        # Save the model with a best loss (test) using postfix: best\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "\n",
    "            record = {\n",
    "                'type_id': stock_industry_type_id,\n",
    "                'target_pct': config_model['target_pct'],\n",
    "                'model_name': model.get_model_name(),\n",
    "                'version': config_model['version'],\n",
    "                'test_loss': test_loss,\n",
    "                'test_acc': test_acc,\n",
    "                'test_precision': test_precision,\n",
    "                'test_recall': test_recall,\n",
    "                'train_loss': train_loss,\n",
    "                'train_acc': train_acc,\n",
    "                'train_precision': train_precision,\n",
    "                'train_recall': train_recall,\n",
    "            }\n",
    "\n",
    "            print(f'Model has saved in {path_model_checkpoint}_best\\n')\n",
    "            print(f'Loss: {test_loss}, Accuracy: {test_acc}%, Precision: {test_precision}%, Recall: {test_recall}%\\n')\n",
    "            model.save(f'{path_model_checkpoint}_best')\n",
    "            Utility.update_model_record_txt(record, path_model_records)\n",
    "\n",
    "# Save the last epoch model using postfix: save\n",
    "print(f'Model has saved in {path_model_checkpoint}_save\\n')\n",
    "model.save(f'{path_model_checkpoint}_save')\n",
    "\n",
    "# del datalaoder_train, datalaoder_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutiple types to train the model.\n",
    "dict_model = {\n",
    "    0: CNNLSTM,\n",
    "    1: TCN,\n",
    "    2: FullyConnected,\n",
    "}\n",
    "\n",
    "model_type_id = 2\n",
    "config_model = {\n",
    "    'n_epochs': 30,\n",
    "    'batch_size': 256,\n",
    "    'version': 4,\n",
    "    'threshold': 0.0,\n",
    "    'target_pct': -0.02,\n",
    "    'window_length':20,\n",
    "    'scale_weight': 0.8,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'use_checkpoint': False,\n",
    "}\n",
    "\n",
    "list_selected_type_id = Set.GetInfo('select_stock_list')\n",
    "\n",
    "for stock_industry_type_id in list_selected_type_id:\n",
    "    list_unique_code_from_data = (SQLSentence.GetCodeByTypeId(stock_industry_type_id, connect))['code'].tolist()\n",
    "    datalaoder_train, datalaoder_test = build_dataloader(main_data, list_unique_code_from_data, config_model)\n",
    "\n",
    "    model = dict_model[model_type_id](datalaoder_train.dataset.shape).to(device)\n",
    "\n",
    "    current_pos_weight = (math.log((Set.GetInfo('pos_weight'))[config_model['target_pct']][dict_type_name[stock_industry_type_id]])+1)*config_model['scale_weight']\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([current_pos_weight]).to(device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config_model['learning_rate'], weight_decay=config_model['weight_decay'])\n",
    "    \n",
    "    path_model_records = f'models/model_records/model_records.csv'\n",
    "    path_model_checkpoint = f'models/checkpoint/type_{stock_industry_type_id}/type_{stock_industry_type_id}_{model.get_model_name()}_Target_{int(config_model[\"target_pct\"]*100)}_v{str(config_model[\"version\"])}'\n",
    "\n",
    "    best_test_loss = Utility.load_best_model_record_txt(stock_industry_type_id, config_model['target_pct'], model.get_model_name(), config_model['version'], path_model_records)\n",
    "\n",
    "    if config_model['use_checkpoint']:\n",
    "        try:\n",
    "            postfix='save'\n",
    "            model.load(f\"{path_model_checkpoint}_{postfix}\")\n",
    "        except:\n",
    "            print(f'No preserved model: {model.get_model_name()}')\n",
    "    \n",
    "    epoch = 0\n",
    "    with tqdm.tqdm(total=config_model['n_epochs'], desc=f'Train {dict_type_name[stock_industry_type_id]}') as pbar:\n",
    "        while epoch < config_model['n_epochs']:\n",
    "            epoch+=1\n",
    "            # print(f'Train {dict_type_name[type_id]} Epoch: {epoch}')\n",
    "\n",
    "            # Train\n",
    "            train_loss, train_acc, train_precision, train_recall = invoke_model('train', model, datalaoder_train, criterion, device, optimizer, config_model['threshold'])\n",
    "\n",
    "            # Test\n",
    "            with torch.no_grad():\n",
    "                test_loss, test_acc, test_precision, test_recall = invoke_model('test', model, datalaoder_test, criterion, device, threshold=config_model['threshold'])\n",
    "\n",
    "                # Save the model with a best loss (test) using postfix: best\n",
    "                if test_loss < best_test_loss:\n",
    "                    best_test_loss = test_loss\n",
    "\n",
    "                    record = {\n",
    "                        'type_id': stock_industry_type_id,\n",
    "                        'target_pct': config_model['target_pct'],\n",
    "                        'model_name': model.get_model_name(),\n",
    "                        'version': config_model['version'],\n",
    "                        'test_loss': test_loss,\n",
    "                        'test_acc': test_acc,\n",
    "                        'test_precision': test_precision,\n",
    "                        'test_recall': test_recall,\n",
    "                        'train_loss': train_loss,\n",
    "                        'train_acc': train_acc,\n",
    "                        'train_precision': train_precision,\n",
    "                        'train_recall': train_recall,\n",
    "                    }\n",
    "\n",
    "                    model.save(f'{path_model_checkpoint}_best')\n",
    "                    Utility.update_model_record_txt(record, path_model_records)\n",
    "                    print(f'Loss: {test_loss}, Accuracy: {test_acc}%, Precision: {test_precision}%, Recall: {test_recall}%\\n')\n",
    "                    print(f'Model has saved in {path_model_checkpoint}_best\\n')\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    model.save(f'{path_model_checkpoint}_save')\n",
    "    print(f'Model has saved in {path_model_checkpoint}_save\\n')\n",
    "\n",
    "    del datalaoder_train, datalaoder_test, model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "target_pct = 0.05\n",
    "window_length = 20\n",
    "threshold=0.5\n",
    "\n",
    "list_selected_type_id = Set.GetInfo('select_stock_list')\n",
    "current_date = (SQLSentence.GetLatestDate(connect)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "model_name = 'CNN_LSTM'\n",
    "ModelClass = getattr(Model, model_name)\n",
    "postfix='best'\n",
    "\n",
    "file_name = f'predict_tmp_{current_date}_{int(target_pct*100)}%_{model_name}_{postfix}.txt'\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        pass\n",
    "\n",
    "with open(file_name, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"----------------------------------Model: {model_name}_{postfix}----------------------------\")\n",
    "\n",
    "    for type_id in tqdm.tqdm(list_selected_type_id):\n",
    "\n",
    "        list_unique_code_from_data = (SQLSentence.GetCodeByTypeId(type_id, connect))['code'].tolist()\n",
    "\n",
    "        model = ModelClass(GetDatasetShape(main_data, window_length)).to(device)\n",
    "        model.eval()\n",
    "        list_code_investable = []\n",
    "\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(f\"{PATH_CHECKPOINT}/type_{type_id}/type_{type_id}_{model.__class__.__name__}_Target_{int(target_pct*100)}_{postfix}\", weights_only=True))\n",
    "        except:\n",
    "            print(f'{dict_type_name[type_id]} No preserved model: {model.__class__.__name__}')\n",
    "            continue\n",
    "\n",
    "        for code in list_unique_code_from_data:\n",
    "            output = predict_result(main_data, code, model, device, target_pct, window_length)\n",
    "            if output > threshold:\n",
    "                list_code_investable.append((code, output))\n",
    "\n",
    "        if len(list_code_investable) != 0:\n",
    "            f.write(\"------------------------------------------------------------------------\")\n",
    "            f.write(f\"\\n產業 {type_id}: {dict_type_name[type_id]}\\n\")\n",
    "            for code, probability in list_code_investable:\n",
    "                f.write(f'{code} {dict_code_name[code]:<10} Prob: {probability}\\n')\n",
    "    f.write(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlstock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
